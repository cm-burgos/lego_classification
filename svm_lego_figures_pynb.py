# -*- coding: utf-8 -*-
"""SVM_Lego_figures.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EABJLxUTYNzxfhrf_7lWey_5uUJM-s1L
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches
import seaborn as sb
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
 
# %matplotlib inline
plt.rcParams['figure.figsize'] = (16, 9)
plt.style.use('ggplot')

from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import DistanceMetric

from sklearn.preprocessing import minmax_scale
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

from sklearn import svm
#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC

dataframe = pd.read_csv(r"lego_data.csv",header=None,sep=',')
dataframe.head(10)

from sklearn.decomposition import PCA, KernelPCA
from sklearn.datasets import make_circles, make_moons, make_classification
from sklearn import decomposition

X = dataframe[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,
               33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,
               61,62,63]].values
print(X)
y = dataframe[64].values
'''
pca = decomposition.PCA(n_components=1)
pca.fit(X)
X = pca.transform(X)
'''
X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.7, random_state=0)


scaler = StandardScaler()# Ejercicio, no use la escalización de los datos a ver que tal funciona!
scaler.fit(X_train)# el fit de los datos solo se hace con el conjunto de entrenamiento!
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

'''
scaler = MinMaxScaler()# Ejercicio, no use la escalización de los datos a ver que tal funciona!
scaler.fit(X_train)# el fit de los datos solo se hace con el conjunto de entrenamiento!
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
'''

kernels=['linear', 'poly', 'rbf', 'sigmoid']
#lineal
#Kernel=0
#msv = svm.SVC(kernel=kernels[Kernel])

#polinomial cuadrático
#Kernel=1
#msv = svm.SVC(kernel=kernels[Kernel],degree=2)

#polinomial cúbico
#Kernel=1
#msv = svm.SVC(kernel=kernels[Kernel],degree=3)
#rbf 
Kernel=3
msv = svm.SVC(kernel=kernels[Kernel],degree=3)
#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC

msv.fit(X_train, y_train)

pred = msv.predict(X_test)
from sklearn.metrics import plot_confusion_matrix
matrix = plot_confusion_matrix(msv, X_test, y_test,
                                 cmap=plt.cm.Blues,
                                 normalize=None)
plt.title('Confusion matrix SVM sigmoid kernel')
plt.show(matrix)
plt.show()
print(classification_report(y_test, pred))
print(accuracy_score(y_test, pred))
print('Accuracy para entrenamiento: '+ str(msv.score(X_train,y_train)))
print('Accuracy para test: '+ str(msv.score(X_test,y_test)))

from sklearn.metrics import matthews_corrcoef
coef=matthews_corrcoef(y_test, pred)
print('El coeficiente de correlación de Matthews es: '+str(coef))

import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
y_score = msv.fit(X_train, y_train).decision_function(X_test)